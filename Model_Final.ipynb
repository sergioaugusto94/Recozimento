{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Model_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioaugusto94/Recozimento/blob/main/Model_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YJcGij2c5V4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "dataset = pd.read_csv('test.csv')\n",
        "\n",
        "dataset = dataset.drop(columns = ['product-type']) \n",
        "\n",
        "# Valores Faltantes\n",
        "dataset.replace('?', np.nan, inplace=True)\n",
        "dataset['formability'] = dataset['formability'].astype(float)\n",
        "dataset.isnull().sum()\n",
        "\n",
        "#Carregando as colunas trabalhadas e eliminando as não usadas\n",
        "colunas_faltantes = pickle.load(open('colunas_faltantes.txt', 'rb'))\n",
        "dataset = dataset.drop(columns = colunas_faltantes)\n",
        "\n",
        "# Foi observado um padrão forte entre a classe 'Ideal' com a coluna 'Temper_rolling'\n",
        "dataset.loc[dataset['temper_rolling'].isnull(), 'temper_rolling'] = 'NULA'\n",
        "dataset.loc[dataset['bf'].isnull(), 'bf'] = 'NULA'\n",
        "dataset.loc[dataset['bl'].isnull(), 'bl'] = 'NULA'\n",
        "dataset.loc[dataset['oil'].isnull(), 'oil'] = 'NULA'\n",
        "dataset.loc[dataset['cbond'].isnull(), 'cbond'] = 'NULA'\n",
        "dataset.loc[dataset['bt'].isnull(), 'bt'] = 'NULA'\n",
        "\n",
        "#----Substituição por Padrão Encontrado\n",
        "dataset.loc[dataset['surface-quality'] == 'E', 'condition'] = 'S' \n",
        "dataset.loc[dataset['surface-quality'] == 'D', 'condition'] = 'S' \n",
        "dataset.loc[dataset['surface-quality'] == 'F', 'condition'] = 'S'\n",
        "dataset.loc[dataset['condition'] == 'A', 'surface-quality'] = 'G' \n",
        "dataset.loc[dataset['steel'] == 'A', 'condition'] = 'S' \n",
        "dataset.loc[dataset['steel'] == 'M', 'surface-quality'] = 'G' \n",
        "dataset.loc[(dataset['surface-quality'] == 'G') & (dataset['condition']=='A'), 'steel'] = 'R'\n",
        "dataset.loc[(dataset['steel'] == 'R') & (dataset['condition'] =='S'), 'surface-quality'] = 'E'\n",
        "dataset.loc[dataset['family'] == 'TN', 'steel'] = 'A'\n",
        "\n",
        "#---Imputação de valores por Regressão Linear\n",
        "colunas_faltantes = []\n",
        "for i in range(len(dataset.isnull().sum())):\n",
        "    if dataset.isnull().sum()[i] > 1:\n",
        "        colunas_faltantes.append(dataset.isnull().sum().index[i])\n",
        "\n",
        "def random_input(df, coluna):\n",
        "    numeros_faltantes = df[coluna].isnull().sum()\n",
        "    valores_observados = df.loc[df[coluna].notnull(),coluna]\n",
        "    df.loc[df[coluna].isnull(), coluna + '_imputation'] = np.random.choice(valores_observados, \n",
        "                                                                           numeros_faltantes, replace = True)\n",
        "    return df\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for coluna in colunas_faltantes:\n",
        "    encoded=dataset.iloc[:, dataset.columns.get_loc(coluna)].values\n",
        "    dataset[coluna + '_imputation'] = dataset[coluna]\n",
        "    dataset = random_input(dataset,coluna)\n",
        "    if coluna != 'formability':\n",
        "        encoded=label_encoder.fit_transform(dataset[coluna + '_imputation'].values)\n",
        "        dataset[coluna + '_imputation'] = dataset[coluna + \n",
        "                                                  '_imputation'].replace(dataset[coluna + \n",
        "                                                                                 '_imputation'].values.tolist(),encoded)\n",
        "\n",
        "coluna_string = []\n",
        "for coluna in dataset.columns.values:\n",
        "    coluna_string.append(coluna) \n",
        "    if colunas_faltantes.count(coluna) > 0:\n",
        "        encoded = dataset.iloc[:,dataset.columns.get_loc(coluna + '_imputation')].values\n",
        "        dataset[coluna] = dataset[coluna].replace(dataset[coluna].values.tolist(), encoded)\n",
        "    if type(dataset[coluna][0]) == str or coluna == 'family':\n",
        "        encoded = label_encoder.fit_transform(dataset[coluna].values)\n",
        "        dataset[coluna] = dataset[coluna].replace(dataset[coluna].values.tolist(), encoded)\n",
        "        \n",
        "from sklearn.linear_model import LinearRegression\n",
        "deter_data = pd.DataFrame(columns = ['Det' + coluna for coluna in colunas_faltantes])\n",
        "for coluna in colunas_faltantes:\n",
        "    deter_data['Det' + coluna] = dataset[coluna + '_imputation']\n",
        "    parameters = list(set(dataset.columns) - set(colunas_faltantes)-{coluna + '_imputation'} - {'recozimento'})\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X = dataset[parameters], y = dataset[coluna + '_imputation'])\n",
        "    \n",
        "    deter_data.loc[dataset[coluna].isnull(), 'Det' + coluna] = model.predict(dataset[parameters])[dataset[coluna].isnull()]\n",
        "    dataset[coluna] = dataset[coluna + '_imputation']\n",
        "    dataset = dataset.drop(columns = coluna + '_imputation')\n",
        "  \n",
        "\n",
        "x_data = dataset.iloc[:, 0:dataset.shape[1] - 1].values\n",
        "ids = dataset.iloc[:, dataset.shape[1] - 1].values\n",
        "\n",
        "    ##--Escalonamento dos dados\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "scaler_data = StandardScaler()\n",
        "x_data = scaler_data.fit_transform(x_data)\n",
        "\n",
        "\n",
        "#---- Importação dos Algoritmos\n",
        "\n",
        "random = pickle.load(open('random_finalizado.sav', 'rb'))\n",
        "knn = pickle.load(open('knn_finalizado.sav', 'rb'))\n",
        "svm = pickle.load(open('svm_finalizado.sav', 'rb'))\n",
        "\n",
        "#---- Outputs dos Algoritmos\n",
        "previsoes_random = random.predict(x_data)\n",
        "previsoes_knn = knn.predict(x_data)\n",
        "previsoes_svm = svm.predict(x_data)\n",
        "\n",
        "#----- Decisão Final\n",
        "prev_final = []\n",
        "for i in range(x_data.shape[0]):\n",
        "    if previsoes_random[i] == 1:\n",
        "        prev_final.append(1)\n",
        "    elif previsoes_knn[i] == 2:\n",
        "        prev_final.append(2)\n",
        "    elif previsoes_random[i] == 0:\n",
        "        prev_final.append(0)\n",
        "    else:\n",
        "        prev_final.append(previsoes_svm[i])\n",
        "        \n",
        "prev_final2 = []\n",
        "for i in prev_final:\n",
        "    if i == 2:\n",
        "        prev_final2.append('ruim')\n",
        "    elif i == 1:\n",
        "        prev_final2.append('mediano')\n",
        "    else:\n",
        "        prev_final2.append('ideal')\n",
        "\n",
        "\n",
        "#--- Criação do Arquivo CSV Final\n",
        "dataset = np.column_stack((ids,prev_final2))\n",
        "previsao_final = pd.DataFrame(dataset,columns=['id','recozimento'])\n",
        "previsao_final.to_csv(r'previsao_final.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}